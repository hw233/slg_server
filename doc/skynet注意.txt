1、内存隐患
在服务处理新消息时，是通过创建新协程来处理的（见co_create），虽然协程会被重复利用，但在当前版本下，这种不断创建协程来消息的方式本身存在不稳定因素：
1、协程只增加不减少，意味过了某个并发高峰后内存不会降下来。
2、创建协程也有一定开销，也占用内存，协程的数量规模不容易控制
3、如果解决第1点，最槽糕的情况是，不断要创建协程，不断要销毁协程，频繁触发gc
这里有一个极端的例子：
如果服务a不断给服务b发消息，但服务b的处理过程存在长时间挂起，这样，对于服务a发来的消息，服务b会不断创建协程去处理，就导致内存被大量占用的情况出现。



2、重入问题
当一个服务call其他服务时，当前协程会挂起，但是这个服务还可以接受并处理其他消息。如果多个协程改到同一个数据，你不做同步处理就无法确定这个数据会是多少。
由于玩家的业务逻辑非常，为了防止重入问题，agent服务也就是玩家服务，不进行任何skynet.call导致的阻塞的调用
其他服务之间如果要用call，需要自己先将该功能思考清楚，有疑问可以拿出来一起讨论。


3、面向函数式编程思想


4、目前，每个服务都有一个唯一的消息队列，且在内存足够的前提下，会无限增长。也就是说，向一个服务发消息是没有失败的可能的。多数情况下，单个服务的消息队列不会太长，在生产消费模型中，也不允许太长。太长意味着消费速度远远低于生产速度，情况多半会恶化。在历史上发生过多起事故，都是和服务过载 有关。http://blog.codingnow.com/2014/10/skynet_overload.html

在 skynet 框架的基础上做设计，需要积累经验。应该尽量去掉单一的热点。如果很多业务流程都经过同一个服务，那么这个服务的处理能力很容易就约束整个系统。
如果这种单点服务无法拆分，那么除了尽可能的优化它（以提高整体处理能力）之外，对其做过载保护也是很有必要的。
可以利用 skynet 内部的 profile 统计单条请求的处理时间也非常重要。找到热点服务中的耗时请求，重点优化。


5、调试
简单答案是，仔细 review 代码，加 log 输出。长一点的答案是，尽量熟悉 skynet 的构造，充分利用预留的监控接口，自己编写工具辅助调试。


6、协议
skynet 的核心并没有规定怎样处理 TCP 的数据流，但在开发网络游戏时，我们往往需要按传统，把 TCP 连接上的数据流分割为一个个数据包。将数据流转换为数据包，比较常见的做法是给数据包加一个长度信息，组装在数据流中。
skynet 提供了一个 lua 库 netpack ，用来把 tcp 流中的数据解析成 长度 + 内容的包。
每个包就是 2 个字节 + 数据内容。这两个字节是 Big-Endian 编码的一个数字。数据内容可以是任意字节。
所以，单个数据包最长不能超过 65535 字节。如果业务层需要传输更大的数据块，请在上层业务协议中解决。

socket.lwrite 可以把一个字符串（一个数据包）写到低优先级通道。只有等默认通道（高优先级）的包全部发送完后，低优先级通道上的包才至少被发送一个（单个包可以保证原子性）。
比如，你可以用它来发送聊天信息，就不会因为聊天信息泛滥把其它重要数据包都塞住。同样，你可以用来发送被分割后的大数据块。如果同时你还有很多其它重要的数据需要传输给客户端，那么这些数据块就会被打散穿插在其间。
当然，你也可以把所有给客户端的数据全部用 lwrite 发送，而仅仅把心跳包放在常规高优先级通道，可以保证心跳频率更稳定。


7、并发问题
这和skynet的调度机制有关。skynet使用全局队列保存了要调度的服务，调度算法是先来先服务。如果某个服务有新消息，就把这个服务加到调度队列中，然后等待调度线程调度。而skynet服务的调度切换依赖于协程的挂起，如果当前调度的服务没有主动挂起或退出，就会一直执行，不调度其他服务了。
这种机制的好处就是实现简单，有利于长作业，上下文切换较少，缺点就是并发效率低，而且像这种长作业的服务超过调度线程数量，就可能导致其他服务饿死。

8.在table.sort中重载比较函数里 不能用call